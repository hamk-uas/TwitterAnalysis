{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b18dedc0",
   "metadata": {},
   "source": [
    "# This Jupyter notebook generates a network graph file for keyword and hashtag relations to each others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e68638ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "##Processed csv file from another notebook\n",
    "filename=\"\"\n",
    "df = pd.read_csv(filename,low_memory=False)\n",
    "df['combine_text'] = df['combine_text'].str.lower()\n",
    "df = df[~df['combine_text'].str.contains('huhu', na=False)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12de51bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "\n",
    "disinformaatio=df[df['combine_text'].str.contains('disinformaatio', regex=False)]\n",
    "disinformaatio['text']=disinformaatio['combine_text'].map(lambda s: [i  for i in s.split() if i.startswith(\"disinformaatio\") ])\n",
    "disinformaatio['keypair'] = \"disinformaatio\"\n",
    "\n",
    "misinformaatio=df[df['combine_text'].str.contains('misinformaatio', regex=False)]\n",
    "misinformaatio['text']=misinformaatio['combine_text'].map(lambda s: [i  for i in s.split() if i.startswith(\"misinformaatio\") ])\n",
    "misinformaatio['keypair'] = \"misinformaatio\"\n",
    "\n",
    "propaganda=df[df['combine_text'].str.contains('propaganda', regex=False)]\n",
    "propaganda['text']=propaganda['combine_text'].map(lambda s: [i  for i in s.split() if i.startswith(\"propaganda\") ])\n",
    "propaganda['keypair'] = \"propaganda\"\n",
    "\n",
    "uutisankka=df[df['combine_text'].str.contains('uutisankka', regex=False)]\n",
    "uutisankka['text']=uutisankka['combine_text'].map(lambda s: [i  for i in s.split() if i.startswith(\"uutisankka\") ])\n",
    "uutisankka['keypair'] = \"uutisankka\"\n",
    "\n",
    "valeuutinen=df[df['combine_text'].str.contains('valeuutinen ', regex=False)]\n",
    "valeuutinen['text']=valeuutinen['combine_text'].map(lambda s: [i  for i in s.split() if i.startswith(\"valeuutinen\") ])\n",
    "valeuutinen['keypair'] = \"valeuutinen\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dab1ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitterData=pd.concat([disinformaatio, misinformaatio, propaganda, uutisankka, valeuutinen], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbfaebb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>hashtag</th>\n",
       "      <th>tweet</th>\n",
       "      <th>keyword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>disinformaatiosta.</td>\n",
       "      <td>[disinformation, valeuutinen]</td>\n",
       "      <td>tweet1</td>\n",
       "      <td>disinformaatio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>disinformaatio</td>\n",
       "      <td>[ilmastokriisi]</td>\n",
       "      <td>tweet6</td>\n",
       "      <td>disinformaatio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>disinformaatio</td>\n",
       "      <td>[ilmastokriisi]</td>\n",
       "      <td>tweet7</td>\n",
       "      <td>disinformaatio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>disinformaatio</td>\n",
       "      <td>[ilmastokriisi]</td>\n",
       "      <td>tweet8</td>\n",
       "      <td>disinformaatio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disinformaatio</td>\n",
       "      <td>[ilmastokriisi]</td>\n",
       "      <td>tweet9</td>\n",
       "      <td>disinformaatio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>valeuutinen</td>\n",
       "      <td>[trumpulos]</td>\n",
       "      <td>tweet8637</td>\n",
       "      <td>valeuutinen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>valeuutinen</td>\n",
       "      <td>[johanbäckman, vaalivilppi, valeuutiset, vaali...</td>\n",
       "      <td>tweet8696</td>\n",
       "      <td>valeuutinen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>valeuutinen</td>\n",
       "      <td>[valeuutinen, fakenews, fakemedia, valemedia]</td>\n",
       "      <td>tweet8713</td>\n",
       "      <td>valeuutinen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>valeuutinen</td>\n",
       "      <td>[valeuutinen, fakenews, medialukutaito]</td>\n",
       "      <td>tweet8717</td>\n",
       "      <td>valeuutinen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>valeuutinen</td>\n",
       "      <td>[äärioikeisto, jekkukissa, disinformaatio, mvl...</td>\n",
       "      <td>tweet8974</td>\n",
       "      <td>valeuutinen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>784 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   text                                            hashtag  \\\n",
       "0    disinformaatiosta.                      [disinformation, valeuutinen]   \n",
       "1        disinformaatio                                    [ilmastokriisi]   \n",
       "2        disinformaatio                                    [ilmastokriisi]   \n",
       "3        disinformaatio                                    [ilmastokriisi]   \n",
       "4        disinformaatio                                    [ilmastokriisi]   \n",
       "..                  ...                                                ...   \n",
       "779         valeuutinen                                        [trumpulos]   \n",
       "780         valeuutinen  [johanbäckman, vaalivilppi, valeuutiset, vaali...   \n",
       "781         valeuutinen      [valeuutinen, fakenews, fakemedia, valemedia]   \n",
       "782         valeuutinen            [valeuutinen, fakenews, medialukutaito]   \n",
       "783         valeuutinen  [äärioikeisto, jekkukissa, disinformaatio, mvl...   \n",
       "\n",
       "         tweet         keyword  \n",
       "0       tweet1  disinformaatio  \n",
       "1       tweet6  disinformaatio  \n",
       "2       tweet7  disinformaatio  \n",
       "3       tweet8  disinformaatio  \n",
       "4       tweet9  disinformaatio  \n",
       "..         ...             ...  \n",
       "779  tweet8637     valeuutinen  \n",
       "780  tweet8696     valeuutinen  \n",
       "781  tweet8713     valeuutinen  \n",
       "782  tweet8717     valeuutinen  \n",
       "783  tweet8974     valeuutinen  \n",
       "\n",
       "[784 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "array2=[]\n",
    "array=[]\n",
    "dataframe_obj={}\n",
    "\n",
    "df2= pd.DataFrame({'text': [], 'hashtag': [], 'tweet': [], 'keyword': []})\n",
    "for index in twitterData.index:\n",
    "    array=[]\n",
    "    dataframe_obj={}\n",
    "    item = twitterData[\"combine_hastags\"][index]\n",
    "    textdata = twitterData[\"text\"][index]\n",
    "    if item != '[]':\n",
    "        if textdata != []:\n",
    "            test=json.loads(item)\n",
    "            tag=[]\n",
    "            for x in test:\n",
    "                tag.append(x['text'].lower())\n",
    "            df2 = df2.append({'text': twitterData[\"text\"][index][0], 'hashtag':  tag, 'tweet': \"tweet\"+str(index),'keyword': twitterData[\"keypair\"][index]}, ignore_index=True)\n",
    "\n",
    "df2        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46ccfa91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nnx.readwrite.gexf.write_gexf(B,\\n  'tags_network.gexf',\\n   encoding='utf-8', version='1.2draft')    \\n   \""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from pylab import rcParams\n",
    "import networkx as nx\n",
    "import nxviz as nv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "mpl.use('tkagg')    #YAAA!!  this finally makes the Damn thing work\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "\n",
    "user_to_hashtags=dict(df2[['keyword','hashtag']].values) #a more convenient data structure: a dictionary with keyword as keys and the list of hashtags they use as values.\n",
    "B=nx.DiGraph() #create an empty graph\n",
    "for i in df2.index: #loop over all the keywords\n",
    "    for hashtag in df2.hashtag[i]: #for each keyword loop over the hashtags they use\n",
    "        if not B.has_edge(df2.keyword[i], hashtag): #if no weight then add 0\n",
    "            B.add_edge(df2.keyword[i],hashtag,weight=0) #add the edge User<->hashtag\n",
    "        B[df2.keyword[i]][hashtag]['weight'] += 1 #if has weight add more wieght to hashtag showing again.\n",
    "\n",
    "nx.readwrite.gexf.write_gexf(B,\n",
    "  'tags_network.gexf',\n",
    "   encoding='utf-8', version='1.2draft')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8923672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('propaganda', 0.002692775257839767),\n",
       " ('disinformaatio', 0.0019727410970662696),\n",
       " ('valeuutinen', 0.00020805828246253866),\n",
       " ('misinformaatio', 9.368069262711163e-05),\n",
       " ('disinformation', 0.0)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the betweenness centrality of G: bet_cen\n",
    "bet_cen = nx.betweenness_centrality(B)\n",
    "# Compute the degree centrality of G: deg_cen\n",
    "deg_cen = nx.degree_centrality(B)\n",
    "# Compute the page rank of G: page_rank\n",
    "page_rank = nx.pagerank(B)\n",
    "# Compute the closeness centrality of G: clos_cen\n",
    "clos_cen = nx.closeness_centrality(B)\n",
    "sorted(bet_cen.items(), key=lambda x:x[1], reverse=True)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8739d1c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "679\n",
      "804\n"
     ]
    }
   ],
   "source": [
    "# How to get the number of nodes\n",
    "print(len(B.nodes()))\n",
    "# How to get the number of edges\n",
    "print(len(B.edges()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fef03f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010706791611818525"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.average_shortest_path_length(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fab1c5b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0017464517053970572"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.density(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e3db5d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09943887007744538"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.average_clustering(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e538c77a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0008594353997312857"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.transitivity(B)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
